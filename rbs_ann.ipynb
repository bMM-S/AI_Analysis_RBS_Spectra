{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and aux functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "#from tensorflow.keras.utils import plot_model\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy import interpolate\n",
    "from keras.utils import plot_model\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_to_nearest(number, lower_limit, upper_limit):\n",
    "    diff_lower = abs(number - lower_limit)\n",
    "    diff_upper = abs(number - upper_limit)\n",
    "    \n",
    "    if diff_lower < diff_upper:\n",
    "        return lower_limit\n",
    "    else:\n",
    "        return upper_limit\n",
    "\n",
    "def mean_squared_difference(list1, list2):\n",
    "    if len(list1) != len(list2):\n",
    "        raise ValueError(\"Lists must have the same length\")\n",
    "    \n",
    "    squared_differences = [(x - y) ** 2 for x, y in zip(list1, list2)]\n",
    "    mean_squared_diff = sum(squared_differences) / len(list1)\n",
    "    \n",
    "    return mean_squared_diff\n",
    "\n",
    "def accuracy(true_labels, predicted_labels):\n",
    "    if len(true_labels) != len(predicted_labels):\n",
    "        raise ValueError(\"Lists must have the same length\")\n",
    "    \n",
    "    correct_predictions = sum(1 for true, pred in zip(true_labels, predicted_labels) if true == pred)\n",
    "    total_predictions = len(true_labels)\n",
    "    \n",
    "    accuracy_value = correct_predictions / total_predictions\n",
    "    return accuracy_value\n",
    "\n",
    "def select_nth_elements(lists, n):\n",
    "    selected_elements = [lst[n] for lst in lists]\n",
    "    return selected_elements\n",
    "\n",
    "def calculate_accuracy(predictions, values):\n",
    "    sum=0\n",
    "    for i in range(len(predictions)):\n",
    "        if predictions[i][1]== values[i][1] and predictions[i][3] == values[i][3] and predictions[i][4] == values[i][4]:\n",
    "            sum+=1\n",
    "    \n",
    "    accuracy=sum/len(predictions)\n",
    "    return accuracy\n",
    "\n",
    "def linear_function(x, m, b):\n",
    "    return m * x + b\n",
    "\n",
    "def quadratic_function(x, a, b, c):\n",
    "    return a * x**2 + b * x + c\n",
    "\n",
    "def increase_data_points(x_original, y_original, num_new_points):\n",
    "\n",
    "    # Generate new x-values evenly spaced between original points\n",
    "    new_x_values = np.linspace(x_original[0], x_original[-1], int(len(x_original) * (num_new_points + 1)))\n",
    "\n",
    "    # Use linear interpolation to estimate new y-values\n",
    "    f = interpolate.interp1d(x_original, y_original, kind='linear')\n",
    "    new_y_values = f(new_x_values)\n",
    "\n",
    "    return new_x_values, new_y_values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN to predict thickness of target (tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network with 1 label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./datafiles/data1.txt', 'r') as file:\n",
    "    input_string = file.read()\n",
    "lines = input_string.split('\\n')\n",
    "x = []\n",
    "for line in lines:\n",
    "    values = line.split()\n",
    "    float_values = [float(value) for value in values]\n",
    "    x.append(float_values)\n",
    "del x[len(x)-1]    \n",
    "\n",
    "with open('./datafiles/labels1.txt', 'r') as file:\n",
    "    input_string = file.read()\n",
    "lines = input_string.split('\\n')\n",
    "y = []\n",
    "for line in lines:\n",
    "    values = line.split()\n",
    "    float_values = [float(value) for value in values]\n",
    "    y.append(float_values)\n",
    "\n",
    "del y[len(y)-1]\n",
    "\n",
    "\n",
    "Xx=[]\n",
    "for array in x:\n",
    "    min_val = np.min(array)\n",
    "    max_val = np.max(array)\n",
    "    normalized_array = (array - min_val) / (max_val - min_val)\n",
    "    Xx.append(normalized_array)\n",
    "\n",
    "X=np.array(Xx)\n",
    "Y=np.array(y)\n",
    "\n",
    "a=np.random.randint(0,len(X))\n",
    "b=np.random.randint(0,len(X))\n",
    "xaxis=np.arange(len(X[0]))\n",
    "fig = plt.figure(figsize =(17, 9))\n",
    "plt.plot(xaxis,X[a],'--')\n",
    "print('Blue graph: Thick:'+str(Y[a][0]))\n",
    "plt.plot(xaxis,X[b],'--')\n",
    "print('Orange graph: Thick:'+str(Y[b][0]))\n",
    "plt.title(' 2 Spectras of Au randomly chosen')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data spliting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state=np.random.randint(0,100)\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.05,random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state=np.random.randint(0,100)\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.05,random_state=random_state)\n",
    "\n",
    "\n",
    "callback = keras.callbacks.EarlyStopping(monitor='loss', patience=15)\n",
    "model=keras.models.Sequential(\n",
    "    [keras.layers.Dense(100,activation='relu',input_shape=(2000,)),\n",
    "     keras.layers.Dense(80,activation='relu'),\n",
    "     keras.layers.Dense(40,activation='relu'),\n",
    "     keras.layers.Dense(1,activation='linear')]\n",
    "     )\n",
    "\n",
    "model.compile(\n",
    "    loss='mean_squared_error', optimizer='adam', metrics=['mae']\n",
    ")\n",
    "\n",
    "epochs = 150\n",
    "batch_size = 32\n",
    "#model.summary()\n",
    "model.fit(X_train,y_train,epochs=epochs,batch_size=batch_size,verbose=1)\n",
    "\n",
    "loss, mae = model.evaluate(X_test, y_test)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "predictions=model.predict(X_test)\n",
    "temp_part, temp_thick, temp_angle, temp_target, temp_energy = [], [], [], [], []\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "\n",
    "    temp_thick.append(predictions[i][0] - y_test[i][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(10, 8))\n",
    "\n",
    "# Plot the histograms on each subplot\n",
    "axs[0, 0].hist(temp_thick, bins=10, color='blue', alpha=0.7)\n",
    "axs[0, 0].set_title('Thickness')\n",
    "axs[0, 0].set_xlabel('Predicted-Real')\n",
    "\n",
    "\n",
    "# Adjust layout to prevent overlapping titles and labels\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predictions vs Real values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(predictions)):\n",
    "\n",
    "    print('Target '+str(i+1)+' :')\n",
    "    print('Thickness: ')\n",
    "    print('P: ' + str(predictions[i][0]) + '. R: ' + str(y_test[i][0]))\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mean Squared Difference and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_squared_difference(select_nth_elements(y_test, 0),select_nth_elements(predictions, 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network with 2 Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./datafiles/data2.txt', 'r') as file:\n",
    "    input_string = file.read()\n",
    "lines = input_string.split('\\n')\n",
    "x = []\n",
    "for line in lines:\n",
    "    values = line.split()\n",
    "    float_values = [float(value) for value in values]\n",
    "    x.append(float_values)\n",
    "del x[len(x)-1]    \n",
    "\n",
    "with open('./datafiles/labels2.txt', 'r') as file:\n",
    "    input_string = file.read()\n",
    "lines = input_string.split('\\n')\n",
    "y = []\n",
    "for line in lines:\n",
    "    values = line.split()\n",
    "    float_values = [float(value) for value in values]\n",
    "    y.append(float_values)\n",
    "\n",
    "del y[len(y)-1]\n",
    "\n",
    "\n",
    "Xx=[]\n",
    "for array in x:\n",
    "    min_val = np.min(array)\n",
    "    max_val = np.max(array)\n",
    "    normalized_array = (array - min_val) / (max_val - min_val)\n",
    "    Xx.append(normalized_array)\n",
    "\n",
    "X=np.array(Xx)\n",
    "Y=np.array(y)\n",
    "\n",
    "a=np.random.randint(0,len(X))\n",
    "b=np.random.randint(0,len(X))\n",
    "xaxis=np.arange(len(X[0]))\n",
    "fig = plt.figure(figsize =(17, 9))\n",
    "plt.plot(xaxis,X[a],'--')\n",
    "print('Blue graph: Thick:'+str(Y[a][0])+' Particle: '+str(Y[a][1]))\n",
    "plt.plot(xaxis,X[b],'--')\n",
    "print('Orange graph: Thick:'+str(Y[b][0])+' Particle: '+str(Y[b][1]))\n",
    "plt.title(' 2 Spectras of Au randomly chosen')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data spliting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state=np.random.randint(0,100)\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.05,random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = keras.callbacks.EarlyStopping(monitor='loss', patience=15)\n",
    "model=keras.models.Sequential(\n",
    "    [keras.layers.Dense(100,activation='relu',input_shape=(2000,)),\n",
    "     keras.layers.Dense(80,activation='relu'),\n",
    "     keras.layers.Dense(50,activation='relu'),\n",
    "     keras.layers.Dense(2,activation='linear')]\n",
    "     )\n",
    "\n",
    "model.compile(\n",
    "    loss='mean_squared_error', optimizer='adam', metrics=['mae']\n",
    ")\n",
    "\n",
    "epochs = 150\n",
    "batch_size = 32\n",
    "#model.summary()\n",
    "model.fit(X_train,y_train,epochs=epochs,batch_size=batch_size,verbose=1)\n",
    "\n",
    "loss, mae = model.evaluate(X_test, y_test)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "predictions=model.predict(X_test)\n",
    "temp_part, temp_thick, temp_angle, temp_target, temp_energy = [], [], [], [], []\n",
    "\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "\n",
    "    predictions[i][1]=round_to_nearest(predictions[i][1], 0, 1)\n",
    "\n",
    "    temp_thick.append(predictions[i][0] - y_test[i][0])\n",
    "    temp_part.append(predictions[i][1] - y_test[i][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(10, 8))\n",
    "\n",
    "# Plot the histograms on each subplot\n",
    "axs[0, 0].hist(temp_thick, bins=20, color='blue', alpha=0.7)\n",
    "axs[0, 0].set_title('Thickness')\n",
    "axs[0, 0].set_xlabel('Predicted-Real')\n",
    "\n",
    "axs[0, 1].hist(temp_part, bins=5, color='green', alpha=0.7)\n",
    "axs[0, 1].set_title('Particle')\n",
    "axs[0, 1].set_xlabel('Predicted-Real')\n",
    "\n",
    "\n",
    "# Adjust layout to prevent overlapping titles and labels\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predictions vs Real values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(predictions)):\n",
    "\n",
    "    print('Target '+str(i+1)+' :')\n",
    "    print('Thickness: ')\n",
    "    print('P: ' + str(predictions[i][0]) + '. R: ' + str(y_test[i][0]))\n",
    "    print('Particle: ')\n",
    "    print('P: ' + str(predictions[i][1]) + '. R: ' + str(y_test[i][1]))\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mean Squared Difference and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_squared_difference(select_nth_elements(y_test, 0),select_nth_elements(predictions, 0)))\n",
    "print(accuracy(select_nth_elements(y_test, 1),select_nth_elements(predictions, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network with 3 Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./datafiles/data3.txt', 'r') as file:\n",
    "    input_string = file.read()\n",
    "lines = input_string.split('\\n')\n",
    "x = []\n",
    "for line in lines:\n",
    "    values = line.split()\n",
    "    float_values = [float(value) for value in values]\n",
    "    x.append(float_values)\n",
    "del x[len(x)-1]    \n",
    "\n",
    "with open('./datafiles/labels3.txt', 'r') as file:\n",
    "    input_string = file.read()\n",
    "lines = input_string.split('\\n')\n",
    "y = []\n",
    "for line in lines:\n",
    "    values = line.split()\n",
    "    float_values = [float(value) for value in values]\n",
    "    y.append(float_values)\n",
    "\n",
    "del y[len(y)-1]\n",
    "\n",
    "\n",
    "Xx=[]\n",
    "for array in x:\n",
    "    min_val = np.min(array)\n",
    "    max_val = np.max(array)\n",
    "    normalized_array = (array - min_val) / (max_val - min_val)\n",
    "    Xx.append(normalized_array)\n",
    "\n",
    "X=np.array(Xx)\n",
    "Y=np.array(y)\n",
    "\n",
    "a=np.random.randint(0,len(X))\n",
    "b=np.random.randint(0,len(X))\n",
    "xaxis=np.arange(len(X[0]))\n",
    "fig = plt.figure(figsize =(17, 9))\n",
    "plt.plot(xaxis,X[a],'--')\n",
    "plt.plot(xaxis,X[b],'--')\n",
    "print('Blue graph: Thick:'+str(Y[a][0])+' Particle: '+str(Y[a][1])+ ' Energy: '+str(Y[a][2]))\n",
    "print('Orange graph: Thick:'+str(Y[b][0])+' Particle: '+str(Y[b][1])+' Energy: '+str(Y[b][2]))\n",
    "plt.title(' 2 Spectras of Au randomly chosen')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data spliting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state=np.random.randint(0,100)\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.05,random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state=np.random.randint(0,100)\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.05,random_state=random_state)\n",
    "\n",
    "\n",
    "callback = keras.callbacks.EarlyStopping(monitor='loss', patience=15)\n",
    "model=keras.models.Sequential(\n",
    "    [keras.layers.Dense(100,activation='relu',input_shape=(1000,)),\n",
    "     keras.layers.Dense(80,activation='relu'),\n",
    "     keras.layers.Dense(50,activation='relu'),\n",
    "     keras.layers.Dense(3,activation='linear')]\n",
    "     )\n",
    "\n",
    "model.compile(\n",
    "    loss='mean_squared_error', optimizer='adam', metrics=['mae']\n",
    ")\n",
    "\n",
    "epochs = 150\n",
    "batch_size = 32\n",
    "#model.summary()\n",
    "model.fit(X_train,y_train,epochs=epochs,batch_size=batch_size,verbose=1)\n",
    "\n",
    "loss, mae = model.evaluate(X_test, y_test)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "predictions=model.predict(X_test)\n",
    "temp_part, temp_thick, temp_angle, temp_target, temp_energy = [], [], [], [], []\n",
    "\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "\n",
    "    predictions[i][1]=round_to_nearest(predictions[i][1], 0, 1)\n",
    "\n",
    "    temp_thick.append(predictions[i][0] - y_test[i][0])\n",
    "    temp_part.append(predictions[i][1] - y_test[i][1])\n",
    "    temp_energy.append(predictions[i][2] - y_test[i][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(10, 8))\n",
    "\n",
    "# Plot the histograms on each subplot\n",
    "axs[0, 0].hist(temp_thick, bins=20, color='blue', alpha=0.7)\n",
    "axs[0, 0].set_title('Thickness')\n",
    "axs[0, 0].set_xlabel('Predicted-Real')\n",
    "\n",
    "axs[0, 1].hist(temp_part, bins=5, color='green', alpha=0.7)\n",
    "axs[0, 1].set_title('Particle')\n",
    "axs[0, 1].set_xlabel('Predicted-Real')\n",
    "\n",
    "axs[1,0].hist(temp_energy, bins=20, color='yellow',alpha=0.7)\n",
    "axs[1,0].set_title('Energy')\n",
    "axs[1,0].set_xlabel('Predicted-Real')\n",
    "\n",
    "\n",
    "# Adjust layout to prevent overlapping titles and labels\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predictions vs Real values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(predictions)):\n",
    "\n",
    "    print('Target '+str(i+1)+' :')\n",
    "    print('Thickness: ')\n",
    "    print('P: ' + str(predictions[i][0]) + '. R: ' + str(y_test[i][0]))\n",
    "    print('Particle: ')\n",
    "    print('P: ' + str(predictions[i][1]) + '. R: ' + str(y_test[i][1]))\n",
    "    print('Energy: ')\n",
    "    print('P: ' + str(predictions[i][2]) + '. R: ' + str(y_test[i][2]))\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mean Squared Difference and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_squared_difference(select_nth_elements(y_test, 0),select_nth_elements(predictions, 0)))\n",
    "print(accuracy(select_nth_elements(y_test, 1),select_nth_elements(predictions, 1)))\n",
    "print(mean_squared_difference(select_nth_elements(y_test, 2),select_nth_elements(predictions, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network with 4 Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./datafiles/data4.txt', 'r') as file:\n",
    "    input_string = file.read()\n",
    "lines = input_string.split('\\n')\n",
    "x = []\n",
    "for line in lines:\n",
    "    values = line.split()\n",
    "    float_values = [float(value) for value in values]\n",
    "    x.append(float_values)\n",
    "del x[len(x)-1]    \n",
    "\n",
    "with open('./datafiles/labels4.txt', 'r') as file:\n",
    "    input_string = file.read()\n",
    "lines = input_string.split('\\n')\n",
    "y = []\n",
    "for line in lines:\n",
    "    values = line.split()\n",
    "    float_values = [float(value) for value in values]\n",
    "    y.append(float_values)\n",
    "\n",
    "del y[len(y)-1]\n",
    "\n",
    "\n",
    "Xx=[]\n",
    "for array in x:\n",
    "    min_val = np.min(array)\n",
    "    max_val = np.max(array)\n",
    "    normalized_array = (array - min_val) / (max_val - min_val)\n",
    "    Xx.append(normalized_array)\n",
    "\n",
    "X=np.array(Xx)\n",
    "Y=np.array(y)\n",
    "\n",
    "a=np.random.randint(0,len(X))\n",
    "b=np.random.randint(0,len(X))\n",
    "xaxis=np.arange(len(X[0]))\n",
    "fig = plt.figure(figsize =(17, 9))\n",
    "plt.plot(xaxis,X[a],'--')\n",
    "print('Blue graph: Thick:'+str(Y[a][0])+' Particle: '+str(Y[a][1])+ ' Energy: '+str(Y[a][2])+' Scatter angle: '+str(Y[a][3]))\n",
    "plt.plot(xaxis,X[b],'--')\n",
    "print('Orange graph: Thick:'+str(Y[b][0])+' Particle: '+str(Y[b][1])+' Energy: '+str(Y[b][2])+' Scatter angle: '+str(Y[b][3]))\n",
    "plt.title(' 2 Spectras of Au randomly chosen')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data spliting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state=np.random.randint(0,100)\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.05,random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state=np.random.randint(0,100)\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.05,random_state=random_state)\n",
    "\n",
    "\n",
    "callback = keras.callbacks.EarlyStopping(monitor='loss', patience=15)\n",
    "model=keras.models.Sequential(\n",
    "    [keras.layers.Dense(100,activation='relu',input_shape=(1000,)),\n",
    "     keras.layers.Dense(80,activation='relu'),\n",
    "     keras.layers.Dense(50,activation='relu'),\n",
    "     keras.layers.Dense(4,activation='linear')]\n",
    "     )\n",
    "\n",
    "model.compile(\n",
    "    loss='mean_squared_error', optimizer='adam', metrics=['mae']\n",
    ")\n",
    "\n",
    "epochs = 150\n",
    "batch_size = 32\n",
    "#model.summary()\n",
    "model.fit(X_train,y_train,epochs=epochs,batch_size=batch_size,verbose=1)\n",
    "\n",
    "loss, mae = model.evaluate(X_test, y_test)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "predictions=model.predict(X_test)\n",
    "temp_part, temp_thick, temp_angle, temp_target, temp_energy = [], [], [], [], []\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "    predictions[i][1]=round_to_nearest(predictions[i][1], 0, 1)\n",
    "    predictions[i][3]=round_to_nearest(predictions[i][3], 140,165)\n",
    "\n",
    "    temp_thick.append(predictions[i][0] - y_test[i][0])\n",
    "    temp_part.append(predictions[i][1] - y_test[i][1])\n",
    "    temp_energy.append(predictions[i][2] - y_test[i][2])\n",
    "    temp_angle.append(predictions[i][3] - y_test[i][3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(10, 8))\n",
    "\n",
    "# Plot the histograms on each subplot\n",
    "axs[0, 0].hist(temp_thick, bins=20, color='blue', alpha=0.7)\n",
    "axs[0, 0].set_title('Thickness')\n",
    "axs[0, 0].set_xlabel('Predicted-Real')\n",
    "\n",
    "axs[0, 1].hist(temp_part, bins=5, color='green', alpha=0.7)\n",
    "axs[0, 1].set_title('Particle')\n",
    "axs[0, 1].set_xlabel('Predicted-Real')\n",
    "\n",
    "axs[1,0].hist(temp_energy, bins=20, color='yellow',alpha=0.7)\n",
    "axs[1,0].set_title('Energy')\n",
    "axs[1,0].set_xlabel('Predicted-Real')\n",
    "\n",
    "axs[1, 1].hist(temp_angle, bins=5, color='red', alpha=0.7)\n",
    "axs[1, 1].set_title('Angle')\n",
    "axs[1, 1].set_xlabel('Predicted-Real')\n",
    "\n",
    "\n",
    "# Adjust layout to prevent overlapping titles and labels\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predictions vs Real values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(predictions)):\n",
    "\n",
    "    print('Target '+str(i+1)+' :')\n",
    "    print('Thickness: ')\n",
    "    print('P: ' + str(predictions[i][0]) + '. R: ' + str(y_test[i][0]))\n",
    "    print('Particle: ')\n",
    "    print('P: ' + str(predictions[i][1]) + '. R: ' + str(y_test[i][1]))\n",
    "    print('Energy: ')\n",
    "    print('P: ' + str(predictions[i][2]) + '. R: ' + str(y_test[i][2]))\n",
    "    print('Angle: ')\n",
    "    print('P: ' + str(predictions[i][3]) + '. R: ' + str(y_test[i][3]))\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mean Squared Difference and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_squared_difference(select_nth_elements(y_test, 0),select_nth_elements(predictions, 0)))\n",
    "print(accuracy(select_nth_elements(y_test, 1),select_nth_elements(predictions, 1)))\n",
    "print(mean_squared_difference(select_nth_elements(y_test, 2),select_nth_elements(predictions, 2)))\n",
    "print(accuracy(select_nth_elements(y_test, 3),select_nth_elements(predictions, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network with 5 Labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data reshaping\n",
    "with open('./datafiles/data5.txt', 'r') as file:\n",
    "    input_string = file.read()\n",
    "lines = input_string.split('\\n')\n",
    "x = []\n",
    "for line in lines:\n",
    "    values = line.split()\n",
    "    float_values = [float(value) for value in values]\n",
    "    x.append(float_values)\n",
    "del x[len(x)-1]    \n",
    "\n",
    "\n",
    "#labels reshaping\n",
    "with open('./datafiles/labels5.txt', 'r') as file:\n",
    "    input_string = file.read()\n",
    "lines = input_string.split('\\n')\n",
    "y = []\n",
    "for line in lines:\n",
    "    values = line.split()\n",
    "    float_values = [float(value) for value in values]\n",
    "    y.append(float_values)\n",
    "del y[len(y)-1]\n",
    "\n",
    "\n",
    "#normalize\n",
    "Xx=[]\n",
    "for array in x:\n",
    "    min_val = np.min(array)\n",
    "    max_val = np.max(array)\n",
    "    normalized_array = (array - min_val) / (max_val - min_val)\n",
    "    Xx.append(normalized_array)\n",
    "\n",
    "#numpy list\n",
    "X=np.array(Xx)\n",
    "Y=np.array(y)\n",
    "\n",
    "\n",
    "#spectra graph\n",
    "a=np.random.randint(0,len(X))\n",
    "b=np.random.randint(0,len(X))\n",
    "xaxis=np.arange(len(X[0]))\n",
    "fig = plt.figure(figsize =(13, 7))\n",
    "plt.plot(xaxis,X[a],'--')\n",
    "plt.plot(xaxis,X[b],'--')\n",
    "print('Blue graph: Thick:'+str(Y[a][0])+' Particle: '+str(Y[a][1])+ ' Energy: '+str(Y[a][2])+' Scatter angle: '+str(Y[a][3])+' Target: '+str(Y[a][4]))\n",
    "print('Orange graph: Thick:'+str(Y[b][0])+' Particle: '+str(Y[b][1])+' Energy: '+str(Y[b][2])+' Scatter angle: '+str(Y[b][3])+' Target: '+str(Y[b][4]))\n",
    "plt.title(' 2 Spectras of Au randomly chosen')\n",
    "plt.show()\n",
    "\n",
    "'''\n",
    "#seperate regression from classification\n",
    "y_rgrss=[]\n",
    "y_clssfr=[]\n",
    "for l in y:\n",
    "    aux=[]\n",
    "    aux.append(l[1])\n",
    "    aux.append(l[3])\n",
    "    aux.append(l[4])\n",
    "    y_clssfr.append(aux)\n",
    "    aux=[]\n",
    "    aux.append(l[0])\n",
    "    aux.append(l[2])\n",
    "    y_rgrss.append(aux)\n",
    "\n",
    "\n",
    "#numpy list\n",
    "Y_rgrss=np.array(y_rgrss)\n",
    "Y_clssfr=np.array(y_clssfr)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data spliting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state=np.random.randint(0,100)\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.05,random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state=np.random.randint(0,100)\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.05,random_state=random_state)\n",
    "\n",
    "\n",
    "callback = keras.callbacks.EarlyStopping(monitor='loss', patience=15)\n",
    "model=keras.models.Sequential(\n",
    "    [keras.layers.Dense(100,activation='relu',input_shape=(1000,)),\n",
    "     keras.layers.Dense(80,activation='relu'),\n",
    "     keras.layers.Dense(50,activation='relu'),\n",
    "     keras.layers.Dense(5,activation='linear')]\n",
    "     )\n",
    "\n",
    "model.compile(\n",
    "    loss='mean_squared_error', optimizer='adam', metrics=['mae']\n",
    ")\n",
    "\n",
    "epochs = 150\n",
    "batch_size = 32\n",
    "#model.summary()\n",
    "model.fit(X_train,y_train,epochs=epochs,batch_size=batch_size,verbose=1)\n",
    "\n",
    "loss, mae = model.evaluate(X_test, y_test)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "predictions=model.predict(X_test)\n",
    "temp_part, temp_thick, temp_angle, temp_target, temp_energy = [], [], [], [], []\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "    predictions[i][1]=round_to_nearest(predictions[i][1], 0, 1)\n",
    "    predictions[i][3]=round_to_nearest(predictions[i][3], 140,165)\n",
    "    predictions[i][4]=round_to_nearest(predictions[i][4], 0,1)\n",
    "\n",
    "    temp_thick.append(predictions[i][0] - y_test[i][0])\n",
    "    temp_part.append(predictions[i][1] - y_test[i][1])\n",
    "    temp_energy.append(predictions[i][2] - y_test[i][2])\n",
    "    temp_angle.append(predictions[i][3] - y_test[i][3])\n",
    "    temp_target.append(predictions[i][4] - y_test[i][4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 2, figsize=(10, 8))\n",
    "\n",
    "# Plot the histograms on each subplot\n",
    "axs[0, 0].hist(temp_thick, bins=20, color='blue', alpha=0.7)\n",
    "axs[0, 0].set_title('Thickness')\n",
    "axs[0, 0].set_xlabel('Predicted-Real')\n",
    "\n",
    "axs[0, 1].hist(temp_part, bins=5, color='green', alpha=0.7)\n",
    "axs[0, 1].set_title('Particle')\n",
    "axs[0, 1].set_xlabel('Predicted-Real')\n",
    "\n",
    "axs[1,0].hist(temp_energy, bins=20, color='yellow',alpha=0.7)\n",
    "axs[1,0].set_title('Energy')\n",
    "axs[1,0].set_xlabel('Predicted-Real')\n",
    "\n",
    "axs[1, 1].hist(temp_angle, bins=5, color='red', alpha=0.7)\n",
    "axs[1, 1].set_title('Angle')\n",
    "axs[1, 1].set_xlabel('Predicted-Real')\n",
    "\n",
    "axs[2, 1].hist(temp_target, bins=5, color='purple', alpha=0.7)\n",
    "axs[2, 1].set_xlim(-1,1)\n",
    "axs[2, 1].set_title('Target')\n",
    "axs[2, 1].set_xlabel('Predicted-Real')\n",
    "\n",
    "\n",
    "# Adjust layout to prevent overlapping titles and labels\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist2d(temp_energy, temp_target)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predictions vs Real values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(predictions)):\n",
    "\n",
    "    print('Target '+str(i+1)+' :')\n",
    "    print('Thickness: ')\n",
    "    print('P: ' + str(predictions[i][0]) + '. R: ' + str(y_test[i][0]))\n",
    "    print('Particle: ')\n",
    "    print('P: ' + str(predictions[i][1]) + '. R: ' + str(y_test[i][1]))\n",
    "    print('Energy: ')\n",
    "    print('P: ' + str(predictions[i][2]) + '. R: ' + str(y_test[i][2]))\n",
    "    print('Angle: ')\n",
    "    print('P: ' + str(predictions[i][3]) + '. R: ' + str(y_test[i][3]))\n",
    "    print('Target: ')\n",
    "    print('P: ' + str(predictions[i][4]) + '. R: ' + str(y_test[i][4]))\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mean Squared Difference and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_squared_difference(select_nth_elements(y_test, 0),select_nth_elements(predictions, 0)))\n",
    "print(accuracy(select_nth_elements(y_test, 1),select_nth_elements(predictions, 1)))\n",
    "print(mean_squared_difference(select_nth_elements(y_test, 2),select_nth_elements(predictions, 2)))\n",
    "print(accuracy(select_nth_elements(y_test, 3),select_nth_elements(predictions, 3)))\n",
    "print(accuracy(select_nth_elements(y_test, 4),select_nth_elements(predictions, 4)))\n",
    "print(calculate_accuracy(predictions,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN testing (5 labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data reshaping\n",
    "with open('./datafiles/data5.txt', 'r') as file:\n",
    "    input_string = file.read()\n",
    "lines = input_string.split('\\n')\n",
    "x = []\n",
    "for line in lines:\n",
    "    values = line.split()\n",
    "    float_values = [float(value) for value in values]\n",
    "    x.append(float_values)\n",
    "del x[len(x)-1]    \n",
    "\n",
    "\n",
    "#labels reshaping\n",
    "with open('./datafiles/labels5.txt', 'r') as file:\n",
    "    input_string = file.read()\n",
    "lines = input_string.split('\\n')\n",
    "y = []\n",
    "for line in lines:\n",
    "    values = line.split()\n",
    "    float_values = [float(value) for value in values]\n",
    "    y.append(float_values)\n",
    "del y[len(y)-1]\n",
    "\n",
    "\n",
    "#normalize\n",
    "Xx=[]\n",
    "for array in x:\n",
    "    min_val = np.min(array)\n",
    "    max_val = np.max(array)\n",
    "    normalized_array = (array - min_val) / (max_val - min_val)\n",
    "    Xx.append(normalized_array)\n",
    "\n",
    "#numpy list\n",
    "X=np.array(Xx)\n",
    "Y=np.array(y)\n",
    "\n",
    "\n",
    "#spectra graph\n",
    "a=np.random.randint(0,len(X))\n",
    "b=np.random.randint(0,len(X))\n",
    "xaxis=np.arange(len(X[0]))\n",
    "fig = plt.figure(figsize =(13, 7))\n",
    "plt.plot(xaxis,X[a],'--')\n",
    "plt.plot(xaxis,X[b],'--')\n",
    "print('Blue graph: Thick:'+str(Y[a][0])+' Particle: '+str(Y[a][1])+ ' Energy: '+str(Y[a][2])+' Scatter angle: '+str(Y[a][3])+' Target: '+str(Y[a][4]))\n",
    "print('Orange graph: Thick:'+str(Y[b][0])+' Particle: '+str(Y[b][1])+' Energy: '+str(Y[b][2])+' Scatter angle: '+str(Y[b][3])+' Target: '+str(Y[b][4]))\n",
    "plt.title(' 2 Spectras of Au randomly chosen')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state=np.random.randint(0,100)\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.05,random_state=random_state)\n",
    "\n",
    "\n",
    "original_shape = X_train.shape\n",
    "X_trainreshape = X_train.reshape((original_shape[0], 1, original_shape[1]))\n",
    "original_shape = X_test.shape\n",
    "X_testreshape = X_test.reshape((original_shape[0], 1, original_shape[1]))\n",
    "\n",
    "callback = keras.callbacks.EarlyStopping(monitor='loss', patience=20)\n",
    "model=keras.models.Sequential(\n",
    "    [keras.layers.SimpleRNN(100,input_shape=(1,1000),return_sequences=True),\n",
    "    keras.layers.Dense(80,activation= 'relu'),\n",
    "    keras.layers.Dense(50,activation= 'relu'),\n",
    "    keras.layers.Dense(5,activation='linear')])\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mae'])\n",
    "\n",
    "plot_model(model, to_file='modelrnn.png', show_shapes=True)\n",
    "\n",
    "epochs = 125\n",
    "batch_size = 32\n",
    "model.fit(X_trainreshape,y_train,epochs=epochs,batch_size=batch_size,verbose=1,callbacks=[callback])\n",
    "\n",
    "loss, mae = model.evaluate(X_testreshape, y_test)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "predictions=model.predict(X_testreshape)\n",
    "predictions = predictions.reshape(len(y_test), 5)\n",
    "temp_part, temp_thick, temp_angle, temp_target, temp_energy = [], [], [], [], []\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "    predictions[i][1]=round_to_nearest(predictions[i][1], 0, 1)\n",
    "    predictions[i][3]=round_to_nearest(predictions[i][3], 140, 165)\n",
    "    predictions[i][4]=round_to_nearest(predictions[i][3], 0, 1)\n",
    "\n",
    "\n",
    "    temp_thick.append(predictions[i][0] - y_test[i][0])\n",
    "    temp_part.append(predictions[i][1] - y_test[i][1])\n",
    "    temp_energy.append(predictions[i][2] - y_test[i][2])\n",
    "    temp_angle.append(predictions[i][3] - y_test[i][3])\n",
    "    temp_target.append(predictions[i][4] - y_test[i][4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Graphs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(10, 8))\n",
    "\n",
    "# Plot the histograms on each subplot\n",
    "axs[0, 0].hist(temp_thick, bins=30, color='blue', alpha=0.7)\n",
    "axs[0, 0].set_title('Thickness')\n",
    "axs[0, 0].set_xlabel('Predicted-Real')\n",
    "\n",
    "axs[0, 1].hist(temp_part, bins=30, color='green', alpha=0.7)\n",
    "axs[0, 1].set_title('Particle')\n",
    "axs[0, 1].set_xlabel('Predicted-Real')\n",
    "\n",
    "axs[1, 0].hist(temp_angle, bins=30, color='red', alpha=0.7)\n",
    "axs[1, 0].set_title('Angle')\n",
    "axs[1, 0].set_xlabel('Predicted-Real')\n",
    "\n",
    "axs[1, 1].hist(temp_target, bins=30, color='purple', alpha=0.7)\n",
    "axs[1, 1].set_title('Target')\n",
    "axs[1, 1].set_xlabel('Predicted-Real')\n",
    "\n",
    "# Adjust layout to prevent overlapping titles and labels\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist2d(temp_energy, temp_angle)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predictions vs Real values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(predictions)):\n",
    "\n",
    "    print('Target '+str(i+1)+' :')\n",
    "    print('Thickness: ')\n",
    "    print('P: ' + str(predictions[i][0]) + '. R: ' + str(y_test[i][0]))\n",
    "    print('Particle: ')\n",
    "    print('P: ' + str(predictions[i][1]) + '. R: ' + str(y_test[i][1]))\n",
    "    print('Energy: ')\n",
    "    print('P: ' + str(predictions[i][2]) + '. R: ' + str(y_test[i][2]))\n",
    "    print('Angle: ')\n",
    "    print('P: ' + str(predictions[i][3]) + '. R: ' + str(y_test[i][3]))\n",
    "    print('Target: ')\n",
    "    print('P: ' + str(predictions[i][4]) + '. R: ' + str(y_test[i][4]))\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mean Squared Difference and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_squared_difference(select_nth_elements(y_test, 0),select_nth_elements(predictions, 0)))\n",
    "print(accuracy(select_nth_elements(y_test, 1),select_nth_elements(predictions, 1)))\n",
    "print(mean_squared_difference(select_nth_elements(y_test, 2),select_nth_elements(predictions, 2)))\n",
    "print(accuracy(select_nth_elements(y_test, 3),select_nth_elements(predictions, 3)))\n",
    "print(accuracy(select_nth_elements(y_test, 4),select_nth_elements(predictions, 4)))\n",
    "print(calculate_accuracy(predictions,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined regression and classification (3 labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experimental data treatment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lead targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./RBS_Runs/2022_23Nov_Pb/1122/alfas/dataRBS1.dat', 'r') as file:\n",
    "    input_string = file.read()\n",
    "lines2 = input_string.split('\\n')\n",
    "test_x = []\n",
    "for line in lines2:\n",
    "    values = line.split()\n",
    "    float_values = [float(value) for value in values]\n",
    "    test_x.append(float_values)\n",
    "\n",
    "del test_x[len(test_x)-1]\n",
    "\n",
    "\n",
    "print(len(test_x))\n",
    "point=[]\n",
    "for j in range(len(test_x)):\n",
    "    for i in range(len(test_x[j])+2):\n",
    "        if test_x[j][i]>test_x[j][i+1]:\n",
    "            point.append(i)\n",
    "            test_x[j]=test_x[j][point[j]:]\n",
    "            break\n",
    "\n",
    "for j in range(len(test_x)):\n",
    "    noise=np.arange(0,250)\n",
    "    params, covariance = curve_fit(quadratic_function, noise, test_x[j][0:250])\n",
    "    fitted_values = quadratic_function(noise,*params)\n",
    "    test_x[j][0:250] = test_x[j][0:250] - (fitted_values)\n",
    "\n",
    "for j in range(len(test_x)):\n",
    "    for i in range(point[j]):\n",
    "        test_x[j].insert(0,0)\n",
    "\n",
    "\n",
    "calibration_factor = 2.36\n",
    "num_new_points = 1.36\n",
    "\n",
    "for j in range(len(test_x)):\n",
    "    xaxis=np.arange(len(test_x[j]))\n",
    "    newx = [x * calibration_factor for x in xaxis]\n",
    "    newx, test_x[j] = increase_data_points(newx, test_x[j], num_new_points)\n",
    "\n",
    "# for j in range(len(test_x)):    \n",
    "#     test_x[j]=test_x[j][90:]\n",
    "    \n",
    "for j in range(len(test_x)):\n",
    "    size=len(test_x[j])\n",
    "    while size<2800:\n",
    "        test_x[j]=np.append(test_x[j],0)\n",
    "        size+=1\n",
    "\n",
    "for j in range(len(test_x)):\n",
    "    for i in range(500):   \n",
    "        test_x[j][i]=0\n",
    "    \n",
    "for j in range(len(test_x)):    \n",
    "    for i in range(len(test_x[j])):\n",
    "        if test_x[j][i]<0:\n",
    "            test_x[j][i]=0\n",
    "\n",
    "Xx=[]\n",
    "for array in test_x:\n",
    "    min_val = np.min(array)\n",
    "    max_val = np.max(array)\n",
    "    normalized_array = (array - min_val) / (max_val - min_val)\n",
    "    Xx.append(normalized_array)\n",
    "'''\n",
    "for array in test_x:\n",
    "    mean=np.mean(array)\n",
    "    std=np.std(array)\n",
    "    new_array=(array-mean)/std\n",
    "    Xx.append(new_array)\n",
    "'''\n",
    "\n",
    "test_x=np.array(Xx)\n",
    "newx=np.arange(0,len(test_x[0]))\n",
    "fig = plt.figure(figsize =(10, 5))\n",
    "# for i in test_x:\n",
    "#     plt.plot(newx,i,'--')\n",
    "plt.plot(newx,test_x[1],'--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gold targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./RBS_Runs/2022_07Set_Au&Pb&C/20220907/labelsRBS1.dat', 'r') as file:\n",
    "    input_string = file.read()\n",
    "lines2 = input_string.split('\\n')\n",
    "test_y = []\n",
    "for line in lines2:\n",
    "    values = line.split()\n",
    "    float_values = [value for value in values]\n",
    "    test_y.append(float_values)\n",
    "\n",
    "del test_y[len(test_y)-1]\n",
    "\n",
    "\n",
    "with open('./RBS_Runs/2022_07Set_Au&Pb&C/20220907/dataRBS1.dat', 'r') as file:\n",
    "    input_string = file.read()\n",
    "lines2 = input_string.split('\\n')\n",
    "test_x = []\n",
    "for line in lines2:\n",
    "    values = line.split()\n",
    "    float_values = [float(value) for value in values]\n",
    "    test_x.append(float_values)\n",
    "\n",
    "del test_x[len(test_x)-1]\n",
    "\n",
    "point=[]\n",
    "for j in range(len(test_x)):\n",
    "    for i in range(len(test_x[j])+2):\n",
    "        if test_x[j][i]>test_x[j][i+1]:\n",
    "            point.append(i)\n",
    "            test_x[j]=test_x[j][point[j]:]\n",
    "            break\n",
    "\n",
    "for j in range(len(test_x)):\n",
    "    noise=np.arange(0,250)\n",
    "    params, covariance = curve_fit(quadratic_function, noise, test_x[j][0:250])\n",
    "    fitted_values = quadratic_function(noise,*params)\n",
    "    test_x[j][0:250] = test_x[j][0:250] - (fitted_values)\n",
    "\n",
    "for j in range(len(test_x)):\n",
    "    for i in range(point[j]):\n",
    "        test_x[j].insert(0,0)\n",
    "\n",
    "\n",
    "calibration_factor = 2.44\n",
    "num_new_points = 1.44\n",
    "\n",
    "for j in range(len(test_x)):\n",
    "    xaxis=np.arange(len(test_x[j]))\n",
    "    newx = [x * calibration_factor for x in xaxis]\n",
    "    newx, test_x[j] = increase_data_points(newx, test_x[j], num_new_points)\n",
    "\n",
    "\n",
    "for j in range(len(test_x)):\n",
    "    for i in range(1450):   \n",
    "        test_x[j][i]=0\n",
    "\n",
    "\n",
    "for j in range(len(test_x)):\n",
    "    size=len(test_x[j])\n",
    "    while size<2800:\n",
    "        test_x[j]=np.append(test_x[j],0)\n",
    "        size+=1\n",
    "    \n",
    "    \n",
    "for j in range(len(test_x)):    \n",
    "    for i in range(len(test_x[j])):\n",
    "        if test_x[j][i]<0:\n",
    "            test_x[j][i]=0\n",
    "\n",
    "Xx=[]\n",
    "for array in test_x:\n",
    "    min_val = np.min(array)\n",
    "    max_val = np.max(array)\n",
    "    normalized_array = (array - min_val) / (max_val - min_val)\n",
    "    Xx.append(normalized_array)\n",
    "'''\n",
    "for array in test_x:\n",
    "    mean=np.mean(array)\n",
    "    std=np.std(array)\n",
    "    new_array=(array-mean)/std\n",
    "    Xx.append(new_array)\n",
    "'''\n",
    "test_x=np.array(Xx)\n",
    "newx=np.arange(0,len(test_x[0]))\n",
    "fig = plt.figure(figsize =(10, 5))\n",
    "for i in test_x:\n",
    "    plt.plot(newx,i,'--')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#seperate regression from classification\n",
    "test_y_rgrss=[]\n",
    "test_y_clssfr=[]\n",
    "for l in test_y:\n",
    "    aux=[]\n",
    "    aux.append(l[2])\n",
    "    test_y_clssfr.append(aux)\n",
    "    aux=[]\n",
    "    aux.append(float(l[0]))\n",
    "    aux.append(float(l[1]))\n",
    "    test_y_rgrss.append(aux)\n",
    "\n",
    "\n",
    "#numpy list\n",
    "test_Y_rgrss=np.array(test_y_rgrss)\n",
    "test_Y_clssfr=np.array(test_y_clssfr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulated data treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./datafiles/datatest2.txt', 'r') as file:\n",
    "    input_string = file.read()\n",
    "lines1 = input_string.split('\\n')\n",
    "\n",
    "with open('./datafiles/labelstest2.txt', 'r') as file:\n",
    "    input_string = file.read()\n",
    "lines2 = input_string.split('\\n')\n",
    "\n",
    "x = []\n",
    "for line in lines1:\n",
    "    values = line.split()\n",
    "    float_values = [float(value) for value in values]\n",
    "    x.append(float_values)\n",
    "del x[len(x)-1]    \n",
    "\n",
    "y = []\n",
    "for line in lines2:\n",
    "    values = line.split()\n",
    "    float_values = [value for value in values]\n",
    "    y.append(float_values)\n",
    "del y[len(y)-1]\n",
    "\n",
    "#data normalization\n",
    "Xx=[]\n",
    "for array in x:\n",
    "    min_val = np.min(array)\n",
    "    max_val = np.max(array)\n",
    "    normalized_array = (array - min_val) / (max_val - min_val)\n",
    "    Xx.append(normalized_array)\n",
    "'''\n",
    "for array in x:\n",
    "    mean=np.mean(array)\n",
    "    std=np.std(array)\n",
    "    new_array=(array-mean)/std\n",
    "    Xx.append(new_array)\n",
    "'''\n",
    "\n",
    "#numpy list\n",
    "X=np.array(Xx)\n",
    "Y=np.array(y)\n",
    "\n",
    "#seperate regression from classification\n",
    "y_rgrss=[]\n",
    "y_clssfr=[]\n",
    "for l in y:\n",
    "    aux=[]\n",
    "    aux.append(l[2])\n",
    "    y_clssfr.append(aux)\n",
    "    aux=[]\n",
    "    aux.append(float(l[0]))\n",
    "    aux.append(float(l[1]))\n",
    "    y_rgrss.append(aux)\n",
    "\n",
    "\n",
    "#numpy list\n",
    "Y_rgrss=np.array(y_rgrss)\n",
    "Y_clssfr=np.array(y_clssfr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spectra graph\n",
    "a=np.random.randint(0,len(X))\n",
    "b=np.random.randint(0,len(X))\n",
    "xaxis=np.arange(len(X[0]))\n",
    "\n",
    "fig = plt.figure(figsize =(10, 5))\n",
    "plt.plot(xaxis,X[a],'--')\n",
    "plt.plot(xaxis,X[b],'--')\n",
    "plt.plot(newx,test_x[0],'--')\n",
    "print('Blue graph: Thick Layer1 : '+str(Y[a][0])+ ' // Thick Layer2 : '+str(Y[a][1])+ ' // Target : '+str(Y[a][2]))\n",
    "print('Orange graph: Thick Layer1 : '+str(Y[b][0])+ ' // Thick Layer2 : '+str(Y[b][1])+ ' // Target : '+str(Y[b][2]))\n",
    "plt.title(' 2 Spectras of Au randomly chosen')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state=np.random.randint(0,500)\n",
    "X_train,X_test,y_train,y_test,y_trainclssfr,y_testclssfr=train_test_split(X,Y_rgrss,Y_clssfr,test_size=0.05,random_state=random_state)\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "y_trainclssfr= encoder.fit_transform(y_trainclssfr.reshape(-1,1))\n",
    "y_testclssfr= encoder.fit_transform(y_testclssfr.reshape(-1,1))\n",
    "# Au CCaF Pb Sn SnAl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model training #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = keras.callbacks.EarlyStopping(monitor='loss', patience=15)\n",
    "input_layer = keras.Input(shape=(2800,), name=\"input_layer\")\n",
    "dense_1 = keras.layers.Dense(80, activation = 'relu', name = 'hidden_1')(input_layer)\n",
    "dense_2 = keras.layers.Dense(40, activation = 'relu', name = 'hidden_2')(dense_1)\n",
    "dense_3 = keras.layers.Dense(20, activation = 'relu', name = 'hidden_3')(dense_2)\n",
    "dense_4 = keras.layers.Dense(5, activation = 'relu', name = 'hidden_4')(dense_3)\n",
    "regression_output = keras.layers.Dense(2, activation = 'linear', name = 'regression_output')(dense_4)\n",
    "classification_output = keras.layers.Dense(5, activation = 'softmax', name = 'classification_output')(dense_4)\n",
    "model = keras.Model(inputs=input_layer,outputs=[regression_output, classification_output])\n",
    "    \n",
    "\n",
    "model.compile(\n",
    "    loss=['mse','categorical_crossentropy'], optimizer='adam', metrics=['mae']\n",
    ")\n",
    "\n",
    "keras.utils.plot_model(model, to_file='test_keras_plot_model.png', show_shapes=True, show_layer_activations=True)\n",
    "IPython.display.Image('test_keras_plot_model.png')\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 64\n",
    "#model.summary()\n",
    "model.fit(X_train,\n",
    "        {\"regression_output\": y_train, \"classification_output\": y_trainclssfr},\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=[callback],\n",
    "        verbose=1)\n",
    "\n",
    "predictions1,predictions2=model.predict(X_test)\n",
    "temp_part, temp_thick1, temp_thick2 = [], [], []\n",
    "\n",
    "\n",
    "for i in range(len(predictions1)):\n",
    "    if predictions1[i][1]<0:\n",
    "        predictions1[i][1] = 0\n",
    "    temp_thick1.append(abs((predictions1[i][0] - y_test[i][0])*(100/y_test[i][0])))\n",
    "    if y_test[i][1]==0:\n",
    "        temp_thick2.append(0)\n",
    "    else:\n",
    "        temp_thick2.append(abs((predictions1[i][1] - y_test[i][1])*(100/y_test[i][1])))\n",
    "    if (np.argmax(predictions2[i]) - np.argmax(y_testclssfr[i]))==0:\n",
    "        temp_part.append(True)\n",
    "    else:\n",
    "        temp_part.append(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "axs[0].hist(temp_thick1, bins=25, color='blue', alpha=0.7)\n",
    "axs[0].set_title('Thickness Layer 1')\n",
    "axs[0].set_xlabel('Percentual deviation')\n",
    "axs[0].set_ylabel('Number of Counts')\n",
    "\n",
    "axs[1].hist(temp_thick2, bins=25, color='red', alpha=0.7)\n",
    "axs[1].set_title('Thickness Layer 2')\n",
    "axs[1].set_xlabel('Percentual deviation')\n",
    "axs[1].set_ylabel('Number of Counts')\n",
    "\n",
    "\n",
    "# Adjust layout to prevent overlapping titles and labels\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_count=temp_part.count(True)\n",
    "false_count=temp_part.count(False)\n",
    "\n",
    "labels=['Correct','Wrong']\n",
    "counts=[true_count, false_count]\n",
    "\n",
    "plt.bar(labels,counts,width=0.35)\n",
    "plt.ylabel('Number of Counts')\n",
    "plt.title('Target')\n",
    "\n",
    "for i, count in enumerate(counts):\n",
    "    plt.text(i, count + 0.1, str(count), ha='center', va='bottom')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predictions vs Real values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(predictions1)):\n",
    "\n",
    "    print('Target '+str(i+1)+' :')\n",
    "    print('Thickness (Layer 1): ')\n",
    "    print('P: ' + str(predictions1[i][0]) + '.\\nR: ' + str(y_test[i][0]))\n",
    "    print('Thickness (Layer 2): ')\n",
    "    print('P: ' + str(predictions1[i][1]) + '.\\nR: ' + str(y_test[i][1]))\n",
    "    print('Target: ')\n",
    "    print('P: ' + str(np.argmax(predictions2[i])) + '.\\nR: ' + str(np.argmax(y_testclssfr[i])))\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model training #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = keras.callbacks.EarlyStopping(monitor='loss', patience=15)\n",
    "input_layer = keras.Input(shape=(2800,), name=\"input_layer\")\n",
    "dense_1 = keras.layers.GaussianNoise(.3, name = 'dense_2')(input_layer)\n",
    "dense_2 = keras.layers.Dense(100, activation = 'relu', name = 'dense_1')(dense_1)\n",
    "dense_3 = keras.layers.Dense(80, activation = 'relu', name = 'dense_3')(dense_2)\n",
    "dense_4 = keras.layers.Dense(50, activation = 'relu', name = 'dense_4')(dense_3)\n",
    "regression_output = keras.layers.Dense(2, activation = 'linear', name = 'regression_output')(dense_4)\n",
    "classification_output = keras.layers.Dense(5, activation = 'softmax', name = 'classification_output')(dense_4)\n",
    "model = keras.Model(inputs=input_layer,outputs=[regression_output, classification_output])\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    loss=['mse','categorical_crossentropy'], optimizer='adam', metrics=['mae']\n",
    ")\n",
    "\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 64\n",
    "#model.summary()\n",
    "model.fit(X_train,\n",
    "        {\"regression_output\": y_train, \"classification_output\": y_trainclssfr},\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=[callback],\n",
    "        verbose=1)\n",
    "\n",
    "#loss, mae = model.evaluate(X_test, y_testclssfr)\n",
    "#print(\"Mean Absolute Error:\", mae)\n",
    "predictions1,predictions2=model.predict(X_test)\n",
    "temp_part, temp_thick1, temp_thick2 = [], [], []\n",
    "\n",
    "\n",
    "for i in range(len(predictions1)):\n",
    "    if predictions1[i][1]<0:\n",
    "        predictions1[i][1] = 0\n",
    "    temp_thick1.append(predictions1[i][0] - y_test[i][0])\n",
    "    temp_thick2.append(predictions1[i][1] - y_test[i][1])\n",
    "    temp_part.append(np.argmax(predictions2[i]) - np.argmax(y_testclssfr[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(10, 8))\n",
    "\n",
    "axs[0, 0].hist(temp_thick1, bins=20, color='blue', alpha=0.7)\n",
    "axs[0, 0].set_title('Thickness Layer 1')\n",
    "axs[0, 0].set_xlabel('Predicted-Real')\n",
    "\n",
    "axs[1, 0].hist(temp_thick2, bins=20, color='blue', alpha=0.7)\n",
    "axs[1, 0].set_title('Thickness Layer 2')\n",
    "axs[1, 0].set_xlabel('Predicted-Real')\n",
    "\n",
    "axs[0, 1].hist(temp_part, bins=20, color='green', alpha=0.7)\n",
    "axs[0, 1].set_title('Target')\n",
    "axs[0, 1].set_xlabel('Predicted-Real')\n",
    "\n",
    "\n",
    "\n",
    "# Adjust layout to prevent overlapping titles and labels\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.hist2d(temp_energy, temp_angle)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predictions vs Real values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(predictions1)):\n",
    "\n",
    "    print('Target '+str(i+1)+' :')\n",
    "    print('Thickness (Layer 1): ')\n",
    "    print('P: ' + str(predictions1[i][0]) + '.\\nR: ' + str(y_test[i][0]))\n",
    "    print('Thickness (Layer 2): ')\n",
    "    print('P: ' + str(predictions1[i][1]) + '.\\nR: ' + str(y_test[i][1]))\n",
    "    print('Target: ')\n",
    "    print('P: ' + str(np.argmax(predictions2[i])) + '.\\nR: ' + str(np.argmax(y_testclssfr[i])))\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experimental test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Y_clssfr= encoder.fit_transform(test_Y_clssfr.reshape(-1,1))\n",
    "\n",
    "predictions1,predictions2=model.predict(test_x)\n",
    "temp_part, temp_thick1, temp_thick2 = [], [], []\n",
    "\n",
    "for i in range(len(predictions1)):\n",
    "    if predictions1[i][1]<0:\n",
    "        predictions1[i][1] = 0\n",
    "    temp_thick1.append(abs((predictions1[i][0] - test_Y_rgrss[i][0])*(100/test_Y_rgrss[i][0])))\n",
    "    if test_Y_rgrss[i][1]==0:\n",
    "        temp_thick2.append(0)\n",
    "    else:\n",
    "        temp_thick2.append(abs((predictions1[i][1] - test_Y_rgrss[i][1])*(100/test_Y_rgrss[i][1])))\n",
    "    if (np.argmax(predictions2[i]) - np.argmax(test_Y_clssfr[i]))==0:\n",
    "        temp_part.append(True)\n",
    "    else:\n",
    "        temp_part.append(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "axs[0].hist(temp_thick1, bins=5, color='blue', alpha=0.7)\n",
    "axs[0].set_title('Thickness Layer 1')\n",
    "axs[0].set_xlabel('Percentual deviation')\n",
    "axs[0].set_ylabel('Number of Counts')\n",
    "\n",
    "axs[1].hist(temp_thick2, bins=5, color='red', alpha=0.7)\n",
    "axs[1].set_title('Thickness Layer 2')\n",
    "axs[1].set_xlabel('Percentual deviation')\n",
    "axs[1].set_ylabel('Number of Counts')\n",
    "\n",
    "\n",
    "# Adjust layout to prevent overlapping titles and labels\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_count=temp_part.count(True)\n",
    "false_count=temp_part.count(False)\n",
    "\n",
    "labels=['Correct','Wrong']\n",
    "counts=[true_count, false_count]\n",
    "\n",
    "plt.bar(labels,counts,width=0.35)\n",
    "plt.ylabel('Number of Counts')\n",
    "plt.title('Target')\n",
    "\n",
    "for i, count in enumerate(counts):\n",
    "    plt.text(i, count, str(count), ha='center', va='bottom')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(predictions1)):\n",
    "\n",
    "    print('Target '+str(i+1)+' :')\n",
    "    print('Thickness (Layer 1): ')\n",
    "    print('P: ' + str(predictions1[i][0]) + '.\\nR: ' + str(test_Y_rgrss[i][0]))\n",
    "    print('Thickness (Layer 2): ')\n",
    "    print('P: ' + str(predictions1[i][1]) + '.\\nR: ' + str(test_Y_rgrss[i][1]))\n",
    "    print('Target: ')\n",
    "    print('P: ' + str(np.argmax(predictions2[i])) + '.\\nR: ' + str(np.argmax(test_Y_clssfr[i])))\n",
    "    print()\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
